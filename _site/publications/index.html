<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3D Vision Lab - Publications.</title>
  <meta name="description" content="3D Vision Lab -- Publications.">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/publications/">
<link rel="shortcut icon" type ="image/x-icon" href="http://localhost:4000/images/favicon.ico">



</head>


  <body>
    
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="http://localhost:4000/"><img src="http://localhost:4000/images/3dv_logo.png" height="32px"/></a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li><a href="http://localhost:4000/members">Members</a></li>
		<li><a href="http://localhost:4000/publications">Publications</a></li>
		<li><a href="http://localhost:4000/class">Class&Workshop</a></li>
		<li><a href="http://localhost:4000/research">Research</a></li>
		<li><a href="http://localhost:4000/gallery">Gallery</a></li>
		<!--<li><a href="http://localhost:4000/openings">Openings</a></li>-->
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid content">
      <div class="row">
        <div id="gridid" class="col-sm-12">
  <h2 id="publications">Publications</h2>
<p><br />
<br /></p>
<h3><span style="color:black">  2026 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/dummy_white.png" /></p>
  <pubtit>Point2Act: Efficient 3D Distillation of Multimodal LLMs for Zero-Shot Context-Aware Grasping</pubtit>
  <p><em>Sang Min Kim, Hyeongjun Heo, Junho Kim, Yonghyeon Lee, Young Min Kim </em><br />
  <strong>IEEE International Conference on Robotics and Automation (ICRA) 2026</strong><br /></p>

  <p><strong><a href="https://sangminkim-99.github.io/point2act/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2508.03099">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/dummy_white.png" /></p>
  <pubtit>3D-aware Disentangled Representation for Compositional Reinforcement Learning</pubtit>
  <p><em>Sungbin Mun, Younghwan Lee, Cheol-Hui Min, Mineui Hong, Young Min Kim </em><br />
  <strong>International Conference on Learning Representations (ICLR) 2026</strong><br /></p>

  <p><strong><a href="https://openreview.net/forum?id=GE0IFoDx8a">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/dummy_white.png" /></p>
  <pubtit>Geometry-Aware Scene Configurations for Novel View Synthesis</pubtit>
  <p><em>Minkwan Kim, Changwoon Choi, Young Min Kim </em><br />
  <strong>IEEE Conference on Virtual Reality and 3D User Interfaces (VR) Posters 2026</strong><br /></p>

  <p><strong><a href="">[pdf]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2025 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/evloc_sample_compressed.gif" /></p>
  <pubtit>Privacy-Preserving Visual Localization with Event Cameras</pubtit>
  <p><em>Junho Kim, Young Min Kim, Ramzi Zahreddine, Weston Anthony Welge, Gurunandan Krishnan, Sizhuo Ma<sup>*</sup><sup>*</sup>, Jian Wang<sup>*</sup><sup>*</sup> </em><br />
  <strong>IEEE Transactions on Image Processing (TIP) 2025</strong><br /></p>

  <p><strong><a href="https://82magnolia.github.io/event_localization/">[project page]</a></strong>
  <strong><a href="https://ieeexplore.ieee.org/document/11175560">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=kk0q690NMXc">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/event_localization">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/hcp_compressed.gif" /></p>
  <pubtit>Humans as a Calibration Pattern: Dynamic 3D Scene Reconstruction from Unsynchronized and Uncalibrated Videos</pubtit>
  <p><em>Changwoon Choi, Jeongjun Kim, Geonho Cha, Minkwan Kim, Dongyoon Wee, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025</strong><br /></p>

  <p><strong><a href="https://changwoonchoi.github.io/HCP">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2412.19089">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/sfcontrol.gif" /></p>
  <pubtit>Motion Synthesis with Sparse and Flexible Keyjoint Control</pubtit>
  <p><em>Inwoo Hwang, Jinseok Bae, Donggeun Lim, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025</strong><br /></p>

  <p><strong><a href="https://inwoohwang.me/SFControl/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2503.15557">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/EDS_teasor.gif" /></p>
  <pubtit>Event-Driven Storytelling with Multiple Lifelike Humans in a 3D scene</pubtit>
  <p><em>Donggeun Lim, Jinseok Bae, Inwoo Hwang, Seungmin Lee, Hwanhee Lee, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025</strong><br /></p>

  <p><strong><a href="https://rms0329.github.io/Event-Driven-Storytelling/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2507.19232">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/scenemi.gif" /></p>
  <pubtit>SceneMI: Motion In-betweening for Modeling Human-Scene Interaction</pubtit>
  <p><em>Inwoo Hwang, Bing Zhou, Young Min Kim, Jian Wang, Chuan Guo </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025, Highlight</strong><br /></p>

  <p><strong><a href="https://inwoohwang.me/SceneMI/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2503.16289">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/less_is_more.gif" /></p>
  <pubtit>Less is More: Improving Motion Diffusion Models with Sparse Keyframes</pubtit>
  <p><em>Jinseok Bae, Inwoo Hwang, Young-Yoon Lee, Ziyu Guo, Joseph Liu, Yizhak Ben-Shabat, Young Min Kim, Mubbasir Kapadia </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025</strong><br /></p>

  <p><strong><a href="https://jinseokbae.github.io/less_is_more/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2503.13859">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/scene_analogies.png" /></p>
  <pubtit>Learning 3D Scene Analogies with Neural Contextual Scene Maps</pubtit>
  <p><em>Junho Kim, Gwangtak Bae, Eun Sun Lee, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2025</strong><br /></p>

  <p><strong><a href="https://82magnolia.github.io/3d_scene_analogies/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2503.15897">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=7JlIV2TPRv8">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/3d_scene_analogies/">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/brepdiff.jpg" /></p>
  <pubtit>BrepDiff: Single-stage B-rep Diffusion Model</pubtit>
  <p><em>Mingi Lee<sup>*</sup>, Dongsu Zhang<sup>*</sup>, Clément Jambon<sup>*</sup>, Young Min Kim </em><br />
  <strong>SIGGRAPH 2025</strong><br /></p>

  <p><strong><a href="https://brepdiff.github.io/">[project page]</a></strong>
  <strong><a href="https://dl.acm.org/doi/10.1145/3721238.3730698">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=qnXEtweEcL4">[video]</a></strong>
  <strong><a href="https://github.com/brepdiff/brepdiff">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/plt_representative_image_v2.jpg" /></p>
  <pubtit>PLT: Part-wise Latent Tokens as Adaptable Motion Priors for Physically Simulated Characters</pubtit>
  <p><em>Jinseok Bae, Younghwan Lee, Donggeun Lim, Young Min Kim </em><br />
  <strong>SIGGRAPH 2025</strong><br /></p>

  <p><strong><a href="https://jinseokbae.github.io/plt">[project page]</a></strong>
  <strong><a href="https://dl.acm.org/doi/10.1145/3721238.3730637">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=gEsvxBneuZE">[video]</a></strong>
  <strong><a href="https://github.com/jinseokbae/plt">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/cvprw_goaldriven.png" /></p>
  <pubtit>Goal-Driven Human Motion Synthesis in Diverse Tasks</pubtit>
  <p><em>Inwoo Hwang, Jinseok Bae, Donggeun Lim, Young Min Kim </em><br />
  <strong>Human Motion Generation (HuMoGen) Workshop at Computer Vision and Pattern Recognition (CVPR) 2025</strong><br /></p>

  <p><strong><a href="">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/eurographics_audio_aided.png" /></p>
  <pubtit>Audio-aided Character Control for Inertial Measurement Tracking</pubtit>
  <p><em>Hojun Jang, Jinseok Bae, Young Min Kim </em><br />
  <strong>European Association for Computer Graphics (Eurographics) short paper 2025</strong><br /></p>

  <p><strong><a href="https://hojunjang17.github.io/AudioCharacter/">[project page]</a></strong>
  <strong><a href="https://diglib.eg.org/server/api/core/bitstreams/23abd870-08bc-4f4b-bf56-c81dd3d953dc/content">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/liv3stroke_cropped.gif" /></p>
  <pubtit>Recovering Dynamic 3D Sketches from Videos</pubtit>
  <p><em>Jaeah Lee, Changwoon Choi, Young Min Kim, Jaesik Park </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2025</strong><br /></p>

  <p><strong><a href="https://jaeah.me/liv3stroke_web/">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2503.20321">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/eurographics_versatile.jpg" /></p>
  <pubtit>Versatile Physics-based Character Control with Hybrid Latent Representation</pubtit>
  <p><em>Jinseok Bae, Jungdam Won, Donggeun Lim, Inwoo Hwang, Young Min Kim </em><br />
  <strong>European Association for Computer Graphics (Eurographics) 2025</strong><br /></p>

  <p><strong><a href="https://jinseokbae.github.io/hybrid_latent_prior/">[project page]</a></strong>
  <strong><a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.70018">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/IRMF_thumbnail.gif" /></p>
  <pubtit>Isometric Regularization for Manifolds of Functional Data</pubtit>
  <p><em>Hyeongjun Heo, Seonghun Oh, Jae Yong Lee, Young Min Kim<sup>*</sup><sup>*</sup>, Yonghyeon Lee<sup>*</sup><sup>*</sup> </em><br />
  <strong>International Conference on Learning Representations (ICLR) 2025</strong><br /></p>

  <p><strong><a href="https://heo0224.github.io/IRMF_projectpage/">[project page]</a></strong>
  <strong><a href="https://openreview.net/forum?id=xBuURiCChw">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/remp.gif" /></p>
  <pubtit>ReMP: Reusable Motion Prior for Multi-domain 3D Human Pose Estimation and Motion Inbetweening</pubtit>
  <p><em>Hojun Jang, Young Min Kim </em><br />
  <strong>IEEE Winter Conference on Applications of Computer Vision (WACV) 2025</strong><br /></p>

  <p><strong><a href="https://hojunjang17.github.io/ReMP/">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/WACV2025/html/Jang_ReMP_Reusable_Motion_Prior_for_Multi-Domain_3D_Human_Pose_Estimation_WACV_2025_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/8P8R-UR7Uzw?si=Hh1wROh6wQ7vBrFp">[video]</a></strong>
  <strong><a href="https://github.com/hojunJang17/ReMP">[code]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2024 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/./multi-agent.gif" /></p>
  <pubtit>Multi-agent Exploration with Similarity Score Map and Topological Memory</pubtit>
  <p><em>Eun Sun Lee, Young Min Kim </em><br />
  <strong>IEEE Robotics and Automation Letters 2024</strong><br /></p>

  <p><strong><a href="https://eunsunlee.github.io/SimScoreMap/">[project page]</a></strong>
  <strong><a href="https://ieeexplore.ieee.org/document/10700601">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=UWpB7UHd3eg">[video]</a></strong>
  <strong><a href="https://github.com/eunsunlee/SimilarityScoreMap">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/i2slam.gif" /></p>
  <pubtit>I<sup>2</sup>-SLAM: Inverting Imaging Process for Robust Photorealistic Dense SLAM</pubtit>
  <p><em>Gwangtak Bae<sup>*</sup>, Changwoon Choi<sup>*</sup>, Hyeongjun Heo, Sang Min Kim, Young Min Kim </em><br />
  <strong>European Conference on Computer Vision (ECCV) 2024</strong><br /></p>

  <p><strong><a href="./I2SLAM">[project page]</a></strong>
  <strong><a href="">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=R4C-ZkVae00">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/asimo.png" /></p>
  <pubtit>ASIMO: Agent-centric Scene representation In Multi-Object manipulation</pubtit>
  <p><em>Cheol-Hui Min, Young Min Kim </em><br />
  <strong>The International Journal of Robotics Research (IJRR), 2024</strong><br /></p>

  <p><strong><a href="https://journals.sagepub.com/doi/10.1177/02783649241257537">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/3doodle.gif" /></p>
  <pubtit>3Doodle: Compact Abstraction of Objects with 3D Strokes</pubtit>
  <p><em>Changwoon Choi, Jaeah Lee, Jaesik Park, Young Min Kim </em><br />
  <strong>SIGGRAPH (ACM Transactions on Graphics) 2024</strong><br /></p>

  <p><strong><a href="https://changwoonchoi.github.io/3Doodle/">[project page]</a></strong>
  <strong><a href="https://dl.acm.org/doi/10.1145/3658156">[pdf]</a></strong>
  <strong><a href="https://github.com/changwoonchoi/3Doodle">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/material_gca.jpg" /></p>
  <pubtit>Investigating Chiral Morphogenesis of Gold Using Generative Cellular Automata</pubtit>
  <p><em>Sang Won Im<sup>*</sup>, Dongsu Zhang<sup>*</sup>, Jeong Hyun Han, Ryeong Myeong Kim, Changwoon Choi, Young Min Kim<sup>*</sup><sup>*</sup>, Ki Tae Nam<sup>*</sup><sup>*</sup> </em><br />
  <strong>Nature Materials 2024</strong><br /></p>

  <p><strong><a href="https://www.nature.com/articles/s41563-024-01889-x">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=J1ElxhGapP4">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/outdoor_hgca_1.gif" /></p>
  <pubtit>Outdoor Scene Extrapolation with Hierarchical Generative Cellular Automata</pubtit>
  <p><em>Dongsu Zhang, Francis Williams, Zan Gojcic, Karsten Kreis, Sanja Fidler, Young Min Kim, Amlan Kar </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024, Highlight</strong><br /></p>

  <p><strong><a href="https://research.nvidia.com/labs/toronto-ai/hGCA/">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Outdoor_Scene_Extrapolation_with_Hierarchical_Generative_Cellular_Automata_CVPR_2024_paper.html">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=96zP8fQFZeM">[video]</a></strong>
  <strong><a href="https://github.com/nv-tlabs/hGCA">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/FGPL.gif" /></p>
  <pubtit>Fully Geometric Panoramic Localization</pubtit>
  <p><em>Junho Kim, Jiwon Jeong, Young Min Kim </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024</strong><br /></p>

  <p><strong><a href="./FGPL">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Fully_Geometric_Panoramic_Localization_CVPR_2024_paper.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/IAHvWwHuuHU">[video]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2023 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/nfl.png" /></p>
  <pubtit>NFL: Normal Field Learning for 6-DoF Grasping of Transparent Objects</pubtit>
  <p><em>Junho Lee, Sang Min Kim, Yonghyeon Lee, Young Min Kim </em><br />
  <strong>IEEE Robotics and Automation Letters 2023</strong><br /></p>

  <p><strong><a href="./NFL">[project page]</a></strong>
  <strong><a href="https://ieeexplore.ieee.org/document/10328050">[pdf]</a></strong>
  <strong><a href="https://youtu.be/b92CTDKeEk8">[video]</a></strong>
  <strong><a href="https://github.com/twjhlee/Normal-Field-Learning">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/ctm.gif" /></p>
  <pubtit>Robust Novel View Synthesis with Color Transform Module</pubtit>
  <p><em>Sang Min Kim, Changwoon Choi, Hyeongjun Heo, Young Min Kim </em><br />
  <strong>Computer Graphics Forum (Pacific Graphics) 2023</strong><br /></p>

  <p><strong><a href="./ColorTransformModule">[project page]</a></strong>
  <strong><a href="../papers/ColorTransformNeRF.pdf">[pdf]</a></strong>
  <strong><a href="https://github.com/sangminkim-99/ColorTransformModule">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/ibl-nerf.png" /></p>
  <pubtit>IBL-NeRF: Image-Based Lighting Formulation of Neural Radiance Fields</pubtit>
  <p><em>Changwoon Choi<sup>*</sup>, Juhyeon Kim<sup>*</sup>, Young Min Kim </em><br />
  <strong>Computer Graphics Forum (Pacific Graphics) 2023</strong><br /></p>

  <p><strong><a href="https://changwoon.info/publications/IBL-NeRF">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2210.08202">[pdf]</a></strong>
  <strong><a href="https://github.com/changwoonchoi/IBL-NeRF">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/mammos.gif" /></p>
  <pubtit>MAMMOS: MApping Multiple human MOtion with Scene understanding and natural interactions</pubtit>
  <p><em>Donggeun Lim, Cheongi Jeong, Young Min Kim </em><br />
  <strong>Computer Vision for Metaverse Workshop at International Conference on Computer Vision (ICCV) 2023</strong><br /></p>

  <p><strong><a href="https://openaccess.thecvf.com/content/ICCV2023W/CV4Metaverse/html/Lim_MAMMOS_MApping_Multiple_Human_MOtion_with_Scene_Understanding_and_Natural_ICCVW_2023_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/Uc6b5ejiyns">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/DynaMesh.gif" /></p>
  <pubtit>Dynamic Mesh Recovery from Partial Point Cloud Sequence</pubtit>
  <p><em>Hojun Jang, Minkwan Kim, Jinseok Bae, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2023</strong><br /></p>

  <p><strong><a href="https://hojunjang17.github.io/DynamicMeshRecovery/">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/OgineYrkgRE">[video]</a></strong>
  <strong><a href="https://github.com/hojunJang17/DynamicMeshRecovery">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Calibrating.gif" /></p>
  <pubtit>Calibrating Panoramic Depth Estimation for Practical Localization and Mapping</pubtit>
  <p><em>Junho Kim, Eun Sun Lee, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2023</strong><br /></p>

  <p><strong><a href="./pano_depth">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/KXz8IwrtJWg">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/LDL.gif" /></p>
  <pubtit>LDL: Line Distance Functions for Panoramic Localization</pubtit>
  <p><em>Junho Kim, Changwoon Choi, Hojun Jang, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2023</strong><br /></p>

  <p><strong><a href="./LDL">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/cQ5l4rauNY0">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/panoramic-localization/">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/PMP.gif" /></p>
  <pubtit>PMP: Learning to Physically Interact with Environments using Multiple Part-wise Motion Priors</pubtit>
  <p><em>Jinseok Bae, Jungdam Won, Donggeun Lim, Cheol-Hui Min and Young Min Kim </em><br />
  <strong>SIGGRAPH 2023</strong><br /></p>

  <p><strong><a href="https://jinseokbae.github.io/pmp">[project page]</a></strong>
  <strong><a href="https://dl.acm.org/doi/fullHtml/10.1145/3588432.3591487">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=WdLGvKdNG-0">[video]</a></strong>
  <strong><a href="https://github.com/jinseokbae/pmp">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/text2scene.gif" /></p>
  <pubtit>Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details</pubtit>
  <p><em>Inwoo Hwang, Hyeonwoo Kim and Young Min Kim </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2023, Highlight</strong><br /></p>

  <p><strong><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Hwang_Text2Scene_Text-Driven_Indoor_Scene_Stylization_With_Part-Aware_Details_CVPR_2023_paper.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/CGIXY2kwIYM">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/egonerf.gif" /></p>
  <pubtit>Balanced Spherical Grid for Egocentric View Synthesis</pubtit>
  <p><em>Changwoon Choi, Sang Min Kim, Young Min Kim </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2023</strong><br /></p>

  <p><strong><a href="https://changwoon.info/publications/EgoNeRF">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Balanced_Spherical_Grid_for_Egocentric_View_Synthesis_CVPR_2023_paper.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/D-lsBhVP8zw">[video]</a></strong>
  <strong><a href="https://github.com/changwoonchoi/EgoNeRF">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/text2pointcloud.png" /></p>
  <pubtit>Text2PointCloud: Text-Driven Stylization for Sparse PointCloud</pubtit>
  <p><em>Inwoo Hwang, Hyeonwoo Kim, Donggeun Lim, Inbum Park and Young Min Kim </em><br />
  <strong>European Association for Computer Graphics (Eurographics) short paper 2023</strong><br /></p>

  <p><strong><a href="https://diglib.eg.org/handle/10.2312/egs20231007">[pdf]</a></strong>
  <strong><a href="https://youtu.be/aGDaKHKv1Xc">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/clopt.jpg" /></p>
  <pubtit>Closed-loop optimization of nanoparticle synthesis enabled by robotics and machine learning</pubtit>
  <p><em>Jungwon Park<em>, Young Min Kim, Seonghun Hong, Byungchan Han, Ki Tae Nam, Yousung Jung</em> </em><br />
  <strong>Matter 2023</strong><br /></p>

  <p><strong><a href="https://www.sciencedirect.com/science/article/abs/pii/S2590238523000449">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/evnerf.gif" /></p>
  <pubtit>Ev-NeRF : Event Based Neural Radiance Field</pubtit>
  <p><em>Inwoo Hwang, Junho Kim, Young Min Kim </em><br />
  <strong>IEEE Winter Conference on Applications of Computer Vision (WACV) 2023</strong><br /></p>

  <p><strong><a href="https://arxiv.org/abs/2206.12455">[pdf]</a></strong>
  <strong><a href="https://youtu.be/dU4Hqr41RUo">[video]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2022 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/moda.jpg" /></p>
  <pubtit>MoDA: Map style transfer for self-supervised Domain Adaptation of embodied agents</pubtit>
  <p><em>Eun Sun Lee, Junho Kim, SangWon Park, and Young Min Kim </em><br />
  <strong>European Conference on Computer Vision (ECCV) 2022</strong><br /></p>

  <p><strong><a href="./MoDA">[project page]</a></strong>
  <strong><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990332.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/j7u47WUZESI">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/cpo.png" /></p>
  <pubtit>CPO: Change Robust Panorama to Point  Cloud Localization</pubtit>
  <p><em>Junho Kim, Hojun Jang, Changwoon Choi, and Young Min Kim </em><br />
  <strong>European Conference on Computer Vision (ECCV) 2022</strong><br /></p>

  <p><strong><a href="./CPO">[project page]</a></strong>
  <strong><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136690173.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/V6XjHL5q0_Y">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/panoramic-localization">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/maskgrasp.gif" /></p>
  <pubtit>MasKGrasp: Mask-based Grasping for Scenes with Multiple General Real-world Objects</pubtit>
  <p><em>Junho Lee, Junhwa Hur, Inwoo Hwang, Young Min Kim </em><br />
  <strong>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/9982130">[pdf]</a></strong>
  <strong><a href="https://youtu.be/pl5WVWQTqDY">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/evtta.png" /></p>
  <pubtit>Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition</pubtit>
  <p><em>Junho Kim, Inwoo Hwang, and Young Min Kim </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022</strong><br /></p>

  <p><strong><a href="./EvTTA">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.html">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=iWvstHPu97Y">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/cgca.gif" /></p>
  <pubtit>Probabilistic Implicit Scene Completion</pubtit>
  <p><em>Dongsu Zhang, Changwoon Choi, Inbum Park, Young Min Kim </em><br />
  <strong>International Conference on Learning Representations (ICLR) 2022, Spotlight</strong><br /></p>

  <p><strong><a href="https://openreview.net/forum?id=BnQhMqDfcKG">[pdf]</a></strong>
  <strong><a href="https://iclr.cc/virtual/2022/spotlight/5911">[video]</a></strong>
  <strong><a href="http://github.com/96lives/gca">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/marionette.gif" /></p>
  <pubtit>Neural Marionette: Unsupervised Learning of Motion Skeleton and Latent Dynamics from Volumetric Video</pubtit>
  <p><em>Jinseok Bae, Hojun Jang, Cheol-Hui Min, Hyungun Choi, Young Min Kim </em><br />
  <strong>AAAI Conference on Artificial Intelligence 2022, Oral</strong><br /></p>

  <p><strong><a href="https://ojs.aaai.org/index.php/AAAI/article/view/19882">[pdf]</a></strong>
  <strong><a href="https://recorder-v3.slideslive.com/?share=59008&amp;s=e4c8ffc0-205b-4fd9-8dcb-84f4745a382a">[video]</a></strong>
  <strong><a href="https://github.com/jinseokbae/neural_marionette">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/domain_adapt_vis_nav.png" /></p>
  <pubtit>Self-Supervised Domain Adaptation for Visual Navigation with Global Map Consistency</pubtit>
  <p><em>Eun Sun Lee, Junho Kim, Young Min Kim </em><br />
  <strong>IEEE Winter Conference on Applications of Computer Vision (WACV) 2022</strong><br /></p>

  <p><strong><a href="./SSDA">[project page]</a></strong>
  <strong><a href="https://arxiv.org/abs/2110.07184">[pdf]</a></strong>
  <strong><a href="https://youtu.be/7nqUENuDp9E">[video]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2021 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/progressive_points.gif" /></p>
  <pubtit>Progressive Growing of Points with Tree-structured Generators</pubtit>
  <p><em>Hyeontae Son, Young Min Kim </em><br />
  <strong>British Machine Vision Conference (BMVC) 2021</strong><br /></p>

  <p><strong><a href="https://bmvc2021-virtualconference.com/conference/papers/paper_0590.html">[pdf]</a></strong>
  <strong><a href="https://github.com/countywest/progressive_growing_of_points">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/path_guiding.gif" /></p>
  <pubtit>Fast and Lightweight Path Guiding Algorithm on GPU</pubtit>
  <p><em>Juhyeon Kim, Young Min Kim </em><br />
  <strong>Pacific Graphics short paper 2021</strong><br /></p>

  <p><strong><a href="https://diglib.eg.org/handle/10.2312/pg20211379">[pdf]</a></strong>
  <strong><a href="https://youtu.be/Ecns4jkeVb4">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/piccolo.png" /></p>
  <pubtit>PICCOLO: Point Cloud-Centric Omnidirectional Localization</pubtit>
  <p><em>Junho Kim, Changwoon Choi, Hojun Jang, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2021</strong><br /></p>

  <p><strong><a href="./PICCOLO">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_PICCOLO_Point_Cloud-Centric_Omnidirectional_Localization_ICCV_2021_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/E-_lEsChfoE">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/panoramic-localization">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/n-imagenet.png" /></p>
  <pubtit>N-ImageNet: Towards Robust, Fine-Grained Object Recognition with Event Cameras</pubtit>
  <p><em>Junho Kim, Jaehyeok Bae, Gangin Park, Dongsu Zhang, Young Min Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2021</strong><br /></p>

  <p><strong><a href="./N-ImageNet">[project page]</a></strong>
  <strong><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_N-ImageNet_Towards_Robust_Fine-Grained_Object_Recognition_With_Event_Cameras_ICCV_2021_paper.html">[pdf]</a></strong>
  <strong><a href="https://youtu.be/7mWPYGRfk-I">[video]</a></strong>
  <strong><a href="https://github.com/82magnolia/n_imagenet">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/s-f-shreds.png" /></p>
  <pubtit>Structure-from-Sherds: Incremental 3D Reassembly of Axially Symmetric Pots from Unordered and Mixed Fragment Collections</pubtit>
  <p><em>Je Hyeong Hong, Seong Jong Yoo, Muhammad Zeeshan Arshad, Young Min Kim, Jinwook Kim </em><br />
  <strong>International Conference on Computer Vision (ICCV) 2021</strong><br /></p>

  <p><strong><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Hong_Structure-From-Sherds_Incremental_3D_Reassembly_of_Axially_Symmetric_Pots_From_Unordered_ICCV_2021_paper.html">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/imat.png" /></p>
  <pubtit>IMAT: The Iterative Medial Axis Transform</pubtit>
  <p><em>Yonghyeon Lee, Jonghyuk Baek, Young Min Kim, Frank Chongwoo Park </em><br />
  <strong>Computer Graphics Forum 2021</strong><br /></p>

  <p><strong><a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.14266">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/autorigging.gif" /></p>
  <pubtit>Auto-rigging 3D Bipedal Characters in Arbitrary Poses</pubtit>
  <p><em>Jeonghwan Kim, Hyeontae Son, Jinseok Bae, Young Min Kim </em><br />
  <strong>European Association for Computer Graphics (Eurographics) short paper 2021</strong><br /></p>

  <p><strong><a href="https://diglib.eg.org/handle/10.2312/egs20211023">[pdf]</a></strong>
  <strong><a href="https://youtu.be/1UVNbxYLkE8">[video]</a></strong>
  <strong><a href="https://github.com/whitealex95/autorigging-bipedal">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/gatsbi.gif" /></p>
  <pubtit>GATSBI: Generative Agent-centric Spatio-temporal Object Interaction</pubtit>
  <p><em>Cheol-Hui Min, Jinseok Bae, Junho Lee, Young Min Kim </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021, Oral</strong><br /></p>

  <p><strong><a href="https://arxiv.org/abs/2104.04275">[pdf]</a></strong>
  <strong><a href="https://youtu.be/nAf87_0T5CE">[video]</a></strong>
  <strong><a href="https://github.com/mch5048/gatsbi">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/gca.gif" /></p>
  <pubtit>Learning to generate 3D shapes with Generative Cellular Automata</pubtit>
  <p><em>Dongsu Zhang, Changwoon Choi, Jeonghwan Kim, Young Min Kim </em><br />
  <strong>International Conference on Learning Representations (ICLR) 2021</strong><br /></p>

  <p><strong><a href="https://openreview.net/forum?id=rABUmU3ulQh">[pdf]</a></strong>
  <strong><a href="https://youtu.be/TKrtiWHfH4Y">[video]</a></strong>
  <strong><a href="http://github.com/96lives/gca">[code]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2020 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/3Dpots.png" /></p>
  <pubtit>3D Pots Configuration System by Optimizing Over Geometric Constraints</pubtit>
  <p><em>Jae Eun Kim, Muhammad Zeeshan Arshad, Seong Jong Yoo, Je Hyeong Hong, Jinwook Kim, Young Min Kim </em><br />
  <strong>International Conference on Pattern Recognition (ICPR) 2020</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9412372">[pdf]</a></strong>
  <strong><a href="https://youtu.be/tdaltLFGFJE">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/SAUM.png" /></p>
  <pubtit>SAUM: Symmetry-Aware Upsampling Module for Consistent Point Cloud Completion</pubtit>
  <p><em>Hyeontae Son, Young Min Kim </em><br />
  <strong>Asian Conference on Computer Vision (ACCV) 2020</strong><br /></p>

  <p><strong><a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Son_SAUM_Symmetry-Aware_Upsampling_Module_for_Consistent_Point_Cloud_Completion_ACCV_2020_paper.pdf">[pdf]</a></strong>
  <strong><a href="https://youtu.be/KhXq75RVowU">[video]</a></strong>
  <strong><a href="https://github.com/countywest/SAUM">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Novel-View-Synthesis.png" /></p>
  <pubtit>Novel View Synthesis with Skip Connections</pubtit>
  <p><em>Ju Hyeon Kim, Young Min Kim </em><br />
  <strong>IEEE International Conference on Image Processing (ICIP) 2020</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/9191076">[pdf]</a></strong>
  <strong><a href="https://youtu.be/szqo3W6K2j8">[video]</a></strong>
  <strong><a href="https://github.com/juhyeonkim95/NovelViewSynthesis">[code]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/GROOT.png" /></p>
  <pubtit>GROOT: A Real-time Streaming System of High-Fidelity Volumetric Videos</pubtit>
  <p><em>Kyungjin Lee, Juheon Yi, Youngki Lee <sup>†</sup>, Sunghyun Choi, Young Min Kim<sup>†</sup> </em><br />
  <strong>ACM International Conference on Mobile Computing and Networking (MobiCom) 2020</strong><br /></p>

  <p><strong><a href="https://dl.acm.org/doi/10.1145/3372224.3419214">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=99r-vb4Pq6k">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Primitive.jpg" /></p>
  <pubtit>Automatic Pose Generation for Robotic 3-D Scanning of Mechanical Parts</pubtit>
  <p><em>Inhwan Lee, Ji Hyun Seo, Young Min Kim, Jonghyun Choi, Soonghung Han, Byounghyun Yoo </em><br />
  <strong>IEEE Transactions on Robotics 2020</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/9089042">[pdf]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  2019 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/PotSAC.png" /></p>
  <pubtit>PotSAC: A Robust Axis Estimator for Axially Symmetric Pot Fragments</pubtit>
  <p><em>Je Hyeong Hong, Young Min Kim, Koang-Chul Wi, Jinwook Kim </em><br />
  <strong>Workshop on e-Heritage at IEEE International Conference on Computer Vision (ICCV)  2019</strong><br /></p>

  <p><strong><a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/EH/Hong_PotSAC_A_Robust_Axis_Estimator_for_Axially_Symmetric_Pot_Fragments_ICCVW_2019_paper.pdf">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/RL-GAN-Net.png" /></p>
  <pubtit>RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion</pubtit>
  <p><em>Muhammad Sarmad, Hyunjoo Jenny Lee<sup>†</sup>, Young Min Kim<sup>†</sup> </em><br />
  <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019</strong><br /></p>

  <p><strong><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sarmad_RL-GAN-Net_A_Reinforcement_Learning_Agent_Controlled_GAN_Network_for_Real-Time_CVPR_2019_paper.pdf">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Planar Abstraction.png" /></p>
  <pubtit>Planar Abstraction and Inverse Rendering of 3D Indoor Environment</pubtit>
  <p><em>Young Min Kim, Sangwoo Ryu, Ig-Jae Kim </em><br />
  <strong>Eurographics short paper 2019 <br /> IEEE Transactions on Visualization and Computer Graphics 2021</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/8936883">[pdf]</a></strong>
  <strong><a href="https://youtu.be/0Ksy75Hl0QM">[video]</a></strong></p>

</div>

<p><br /></p>
<h3><span style="color:black">  before 2019 </span></h3>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/3D Modeling.png" /></p>
  <pubtit>3D Modeling from Photos Given Topological Information</pubtit>
  <p><em>Young Min Kim, Junghyun Cho, Sang Chul Ahn </em><br />
  <strong>IEEE Transactions on Visualization and Computer Graphics 2016</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/7346503">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Guided Real-Time.png" /></p>
  <pubtit>Guided Real-Time Scanning of Indoor Objects</pubtit>
  <p><em>Young Min Kim, Niloy J. Mitra, Qixing Huang, Leonidas Guibas </em><br />
  <strong>Pacific Graphics (Computer Graphics Forum) 2013</strong><br /></p>

  <p><strong><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12225">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=HLrUMjKCbOc">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Acquiring 3D.png" /></p>
  <pubtit>Acquiring 3D Indoor Environments with Variability and Repetition</pubtit>
  <p><em>Young Min Kim, Niloy J. Mitra, Dongming Yan, Leonidas Guibas </em><br />
  <strong>SIGGRAPH ASIA (Transactions on Graphics) 2012</strong><br /></p>

  <p><strong><a href="https://dl.acm.org/doi/10.1145/2366145.2366157">[pdf]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Interactive Acquisition.png" /></p>
  <pubtit>Interactive Acquisition of Residential Floor Plans</pubtit>
  <p><em>Young Min Kim, Jen Dolson, Mike Sokolsky, Vladlen Koltun, Sebastian Thrun </em><br />
  <strong>IEEE International Conference on Robotics and Animation (ICRA) 2012</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/6224595">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=SG5Wltm1U04">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Multi-view Image.png" /></p>
  <pubtit>Multi-view Image and ToF Sensor Fusion for Dense 3D Reconstruction</pubtit>
  <p><em>Y.M. Kim, C. Theobalt, J. Diebel, J. Kosecka, B. Micusik, S. Thrun </em><br />
  <strong>IEEE Workshop on 3-D Digital Imaging and Modeling (3DIM) at the International Conference on Computer Vision (ICCV) 2009</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/5457430">[pdf]</a></strong>
  <strong><a href="https://www.youtube.com/watch?v=VEoI3uaqjLw">[video]</a></strong></p>

</div>

<div class="pub" style="display: inline-block; width: 100%; margin: 20px 0 20px 0">
  <p><img src="http://localhost:4000/images/pubpic/Design and Calibration.png" /></p>
  <pubtit>Design and Calibration of Multi-View TOF Sensor Fusion System</pubtit>
  <p><em>Y.M. Kim, D. Chan, C. Theobalt, S. Thrun </em><br />
  <strong>IEEE Workshop on Time-of-flight Computer Vision at Conference on Computer Vision and Pattern Recognition (CVPR) 2008</strong><br /></p>

  <p><strong><a href="https://ieeexplore.ieee.org/document/4563160">[pdf]</a></strong></p>

</div>


</div>

      </div>
    </div>

    <div class="panel-info" style = "background-color: black">
  <div class="container-fluid">
      <div class="row">
        <div class="col-md-8" style = " font-size:0.8em;  color: darkgrey;">  Copyright 2024, 3D Vision Laboratory, Dept. of Electrical and Computer Engineering, Seoul National University. </div>
        <div class="col-md-8" style = " font-size:0.8em;  color: darkgrey;">
          Contact: Room 916, Building 301, 1 Gwanak-ro, Gwanak-gu, Seoul, Republic of Korea
        </div>
      </div>
  </div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script>
<script src="http://localhost:4000/js/custom_style.js"></script>

  </body>

</html>
